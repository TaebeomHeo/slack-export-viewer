import os
import hashlib
import urllib.parse
import requests
import logging
from pathlib import Path
from urllib.parse import urlparse, parse_qs
import mimetypes
import time
import re

class ExternalResourceDownloader:
    """
    ì™¸ë¶€ ë¦¬ì†ŒìŠ¤(ì´ë¯¸ì§€, ì²¨ë¶€íŒŒì¼ ë“±)ë¥¼ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    def __init__(self, output_dir, download_dir="external_resources", slack_token=None):
        self.output_dir = Path(output_dir)
        self.download_dir = self.output_dir / download_dir
        self.download_dir.mkdir(parents=True, exist_ok=True)
        
        # Slack í† í° (Bearer ì¸ì¦ìš©)
        self.slack_token = slack_token
        
        # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë“¤ì˜ ë§¤í•‘ (URL -> ë¡œì»¬ ê²½ë¡œ)
        self.downloaded_files = {}
        
        # ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ ë°©ì§€ë¥¼ ìœ„í•œ ìºì‹œ
        self.download_cache = {}
        
        # ì„¸ì…˜ ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Slack-Export-Viewer/3.3.1'
        })
        
        # Slack í† í°ì´ ìˆìœ¼ë©´ Bearer í† í° ì„¤ì •
        if self.slack_token:
            self.session.headers.update({
                'Authorization': f'Bearer {self.slack_token}'
            })
            logging.info("Slack í† í°ì´ ì„¤ì •ë˜ì–´ ì¸ì¦ëœ ìš”ì²­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ë‹¤ìš´ë¡œë“œ í†µê³„
        self.stats = {
            'total_attempted': 0,
            'total_success': 0,
            'total_failed': 0,
            'total_skipped': 0
        }
        
        # ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë“¤ì„ ìºì‹œì— ë¡œë“œ
        self._load_existing_files()
        
        logging.info(f"ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì €ì¥ ìœ„ì¹˜: {self.download_dir}")
    
    def _load_existing_files(self):
        """
        ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë“¤ì„ ìºì‹œì— ë¡œë“œí•©ë‹ˆë‹¤.
        """
        if not self.download_dir.exists():
            return
        
        existing_files = list(self.download_dir.glob('*'))
        if existing_files:
            logging.info(f"ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ {len(existing_files)}ê°œë¥¼ ìºì‹œì— ë¡œë“œí•©ë‹ˆë‹¤.")
            print(f"ğŸ“ ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ {len(existing_files)}ê°œë¥¼ ìºì‹œì— ë¡œë“œí•©ë‹ˆë‹¤.")
            
            # íŒŒì¼ëª…ì—ì„œ URL í•´ì‹œë¥¼ ì¶”ì¶œí•˜ì—¬ ìºì‹œì— ì¶”ê°€
            for file_path in existing_files:
                if file_path.is_file():
                    filename = file_path.name
                    
                    # íŒŒì¼ëª…ì—ì„œ í•´ì‹œ ë¶€ë¶„ ì¶”ì¶œ (ë§ˆì§€ë§‰ 8ìë¦¬)
                    # í™•ì¥ìê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                    if '_' in filename:
                        parts = filename.split('_')
                        if len(parts) >= 2:
                            # ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œ í™•ì¥ì ì œê±° í›„ í•´ì‹œ í™•ì¸
                            last_part = parts[-1]
                            if '.' in last_part:
                                # í™•ì¥ìê°€ ìˆëŠ” ê²½ìš°
                                url_hash = last_part.split('.')[0]
                            else:
                                # í™•ì¥ìê°€ ì—†ëŠ” ê²½ìš°
                                url_hash = last_part
                            
                            # 8ìë¦¬ í•´ì‹œì¸ì§€ í™•ì¸ (ì•ŒíŒŒë²³ê³¼ ìˆ«ìë§Œ)
                            if len(url_hash) == 8 and url_hash.isalnum():
                                # í•´ì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹œ í‚¤ ìƒì„± (ì‹¤ì œ URLì€ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ íŒŒì¼ëª… ê¸°ë°˜)
                                cache_key = f"local_file_{url_hash}"
                                relative_path = str(file_path.relative_to(self.output_dir))
                                self.download_cache[cache_key] = relative_path
                                self.stats['total_skipped'] += 1
                                logging.debug(f"ìºì‹œì— ë¡œë“œ: {filename} -> {cache_key}")
            
            logging.info(f"ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(self.download_cache)}ê°œ íŒŒì¼")
            print(f"âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(self.download_cache)}ê°œ íŒŒì¼")
        else:
            logging.info("ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ“ ê¸°ì¡´ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def _extract_token_from_url(self, url):
        """
        URLì—ì„œ Slack í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        t= íŒŒë¼ë¯¸í„°ì—ì„œ xoxe- ë˜ëŠ” xoxb- í† í°ì„ ì°¾ìŠµë‹ˆë‹¤.
        """
        try:
            parsed_url = urlparse(url)
            query_params = parse_qs(parsed_url.query)
            
            # t íŒŒë¼ë¯¸í„°ì—ì„œ í† í° ì¶”ì¶œ
            if 't' in query_params:
                token = query_params['t'][0]
                if token.startswith(('xoxe-', 'xoxb-')):
                    return token
            
            # URLì— ì§ì ‘ í† í°ì´ í¬í•¨ëœ ê²½ìš° (ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œ)
            token_pattern = r't=xox[eb]-\w+'
            match = re.search(token_pattern, url)
            if match:
                token = match.group(0).split('=')[1]
                return token
                
        except Exception as e:
            logging.debug(f"URLì—ì„œ í† í° ì¶”ì¶œ ì‹¤íŒ¨: {url} - {str(e)}")
        
        return None
    
    def get_safe_filename(self, url, content_type=None):
        """
        URLì—ì„œ ì•ˆì „í•œ íŒŒì¼ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
        ì¤‘ë³µì„ ë°©ì§€í•˜ê¸° ìœ„í•´ URL í•´ì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„
        parsed_url = urlparse(url)
        original_filename = os.path.basename(parsed_url.path)
        
        # URL í•´ì‹œ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        
        # í™•ì¥ì ê²°ì • (ìš°ì„ ìˆœìœ„: URL ê²½ë¡œ > Content-Type > ê¸°ë³¸ê°’)
        ext = ''
        
        # 1. URL ê²½ë¡œì—ì„œ í™•ì¥ì ì¶”ì¶œ
        if original_filename and '.' in original_filename:
            ext = os.path.splitext(original_filename)[1]
        
        # 2. Content-Typeì—ì„œ í™•ì¥ì ì¶”ì¶œ (URLì—ì„œ í™•ì¥ìë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°)
        if not ext and content_type:
            guessed_ext = mimetypes.guess_extension(content_type)
            if guessed_ext:
                ext = guessed_ext
        
        # 3. ê¸°ë³¸ í™•ì¥ì (ì´ë¯¸ì§€ì¸ ê²½ìš°)
        if not ext and content_type and 'image' in content_type:
            if 'jpeg' in content_type or 'jpg' in content_type:
                ext = '.jpg'
            elif 'png' in content_type:
                ext = '.png'
            elif 'gif' in content_type:
                ext = '.gif'
            elif 'webp' in content_type:
                ext = '.webp'
            else:
                ext = '.bin'  # ë°”ì´ë„ˆë¦¬ íŒŒì¼
        
        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        if original_filename and '.' in original_filename:
            name = os.path.splitext(original_filename)[0]
            # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì•ˆì „í•œ ë¬¸ìë¡œ ë³€í™˜
            safe_name = "".join(c for c in name if c.isalnum() or c in ('-', '_'))[:50]
            filename = f"{safe_name}_{url_hash}{ext}"
        else:
            filename = f"resource_{url_hash}{ext}"
        
        return filename
    
    def download_file(self, url, retry_count=3):
        """
        íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì€ ìºì‹œì—ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if not url or not url.startswith(('http://', 'https://')):
            logging.debug(f"ìœ íš¨í•˜ì§€ ì•Šì€ URL ìŠ¤í‚µ: {url}")
            return None
        
        self.stats['total_attempted'] += 1
        
        # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì¸ì§€ í™•ì¸
        if url in self.downloaded_files:
            logging.debug(f"ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ìŠ¤í‚µ: {url}")
            self.stats['total_skipped'] += 1
            return self.downloaded_files[url]
        
        # ìºì‹œì—ì„œ í™•ì¸
        if url in self.download_cache:
            logging.debug(f"ìºì‹œì—ì„œ ì°¾ì€ íŒŒì¼ ìŠ¤í‚µ: {url}")
            self.stats['total_skipped'] += 1
            return self.download_cache[url]
        
        # URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œí•˜ì—¬ ë¡œê·¸ì— í‘œì‹œ
        try:
            domain = urlparse(url).netloc
            logging.info(f"[{domain}] ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")
        except:
            logging.info(f"ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")
        
        filename = None
        for attempt in range(retry_count):
            try:
                if attempt > 0:
                    logging.info(f"  ì¬ì‹œë„ {attempt + 1}/{retry_count}: {url}")
                
                # URLì—ì„œ í† í° ì¶”ì¶œ ì‹œë„
                url_token = self._extract_token_from_url(url)
                
                # Slack CDN URLì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆí•œ í—¤ë” ì„¤ì •
                headers = {}
                if self._is_slack_cdn_url(url):
                    if url_token:
                        # URLì—ì„œ ì¶”ì¶œí•œ í† í° ì‚¬ìš©
                        headers['Authorization'] = f'Bearer {url_token}'
                        logging.debug(f"  URLì—ì„œ ì¶”ì¶œí•œ í† í° ì‚¬ìš©: {url_token[:10]}...")
                    elif self.slack_token:
                        # ì„¤ì •ëœ í† í° ì‚¬ìš©
                        headers['Authorization'] = f'Bearer {self.slack_token}'
                        logging.debug("  ì„¤ì •ëœ Slack í† í° ì‚¬ìš©")
                    else:
                        logging.warning("  Slack CDN URLì´ì§€ë§Œ í† í°ì´ ì—†ì–´ ì¸ì¦ ì—†ì´ ì‹œë„í•©ë‹ˆë‹¤.")
                
                response = self.session.get(url, timeout=10, stream=True, headers=headers)
                response.raise_for_status()
                
                # Content-Type í™•ì¸
                content_type = response.headers.get('content-type', '').split(';')[0]
                content_length = response.headers.get('content-length')
                
                if content_length:
                    logging.info(f"  íŒŒì¼ í¬ê¸°: {int(content_length):,} bytes")
                
                # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
                filename = self.get_safe_filename(url, content_type)
                file_path = self.download_dir / filename
                
                # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ë‹¤ë¥¸ URLì—ì„œ ê°™ì€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œ ê²½ìš°)
                if file_path.exists():
                    logging.info(f"  íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•¨: {filename}")
                    print(f"  ğŸ“ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•¨: {filename}")
                    self.download_cache[url] = str(file_path.relative_to(self.output_dir))
                    self.stats['total_skipped'] += 1
                    return self.download_cache[url]
                
                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                downloaded_size = 0
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                
                logging.info(f"  ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename} ({downloaded_size:,} bytes)")
                print(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename} ({downloaded_size:,} bytes)")
                
                # ì„±ê³µ ì‹œ ìºì‹œì— ì €ì¥
                relative_path = str(file_path.relative_to(self.output_dir))
                self.downloaded_files[url] = relative_path
                self.download_cache[url] = relative_path
                
                self.stats['total_success'] += 1
                return relative_path
                
            except Exception as e:
                logging.warning(f"  ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retry_count}): {str(e)}")
                print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retry_count}): {str(e)}")
                if attempt < retry_count - 1:
                    time.sleep(1)  # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
                else:
                    logging.error(f"  ë‹¤ìš´ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {url} - {str(e)}")
                    print(f"  ğŸ’¥ ë‹¤ìš´ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {url} - {str(e)}")
                    self.stats['total_failed'] += 1
                    return None
        
        return None
    
    def _is_slack_cdn_url(self, url):
        """
        URLì´ Slack CDN URLì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        """
        slack_domains = [
            'a.slack-edge.com',
            'files.slack.com',
            'slack-files.com',
            'slack-imgs.com'
        ]
        
        parsed_url = urlparse(url)
        return any(domain in parsed_url.netloc for domain in slack_domains)
    
    def get_local_path(self, url):
        """
        URLì— ëŒ€í•œ ë¡œì»¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ë‹¤ìš´ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        return self.downloaded_files.get(url) or self.download_cache.get(url)
    
    def download_all_resources(self, messages):
        """
        ëª¨ë“  ë©”ì‹œì§€ì—ì„œ ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì•„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
        """
        print(f"ğŸ” download_all_resources í•¨ìˆ˜ ì‹œì‘! ë©”ì‹œì§€ ê°œìˆ˜: {len(messages)}")
        logging.info(f"ğŸ” download_all_resources í•¨ìˆ˜ ì‹œì‘! ë©”ì‹œì§€ ê°œìˆ˜: {len(messages)}")
        
        # ì²« ë²ˆì§¸ ë©”ì‹œì§€ êµ¬ì¡° í™•ì¸
        if messages:
            first_msg = messages[0]
            print(f"ğŸ“‹ ì²« ë²ˆì§¸ ë©”ì‹œì§€ íƒ€ì…: {type(first_msg)}")
            print(f"ğŸ“‹ ì²« ë²ˆì§¸ ë©”ì‹œì§€ ì†ì„±ë“¤: {dir(first_msg)}")
            logging.info(f"ğŸ“‹ ì²« ë²ˆì§¸ ë©”ì‹œì§€ íƒ€ì…: {type(first_msg)}")
            logging.info(f"ğŸ“‹ ì²« ë²ˆì§¸ ë©”ì‹œì§€ ì†ì„±ë“¤: {dir(first_msg)}")
        
        total_resources = 0
        downloaded_count = 0
        
        logging.info(f"ë©”ì‹œì§€ì—ì„œ ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì‹œì‘... (ì´ {len(messages)}ê°œ ë©”ì‹œì§€)")
        print(f"ğŸš€ ë©”ì‹œì§€ì—ì„œ ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì‹œì‘... (ì´ {len(messages)}ê°œ ë©”ì‹œì§€)")
        
        for i, message in enumerate(messages):
            if i % 50 == 0:  # 50ê°œë§ˆë‹¤ ì§„í–‰ë¥  í‘œì‹œ
                logging.info(f"ì§„í–‰ë¥ : {i}/{len(messages)} ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ ({i/len(messages)*100:.1f}%)")
                print(f"ğŸ“Š ì§„í–‰ë¥ : {i}/{len(messages)} ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ ({i/len(messages)*100:.1f}%)")
            
            message_resources = []  # í˜„ì¬ ë©”ì‹œì§€ì—ì„œ ë°œê²¬ëœ ë¦¬ì†ŒìŠ¤ë“¤
            
            # ì‚¬ìš©ì í”„ë¡œí•„ ì´ë¯¸ì§€
            if hasattr(message, 'img') and message.img:
                total_resources += 1
                message_resources.append(f"í”„ë¡œí•„ ì´ë¯¸ì§€: {message.img}")
                if self.download_file(message.img):
                    downloaded_count += 1
            
            # ì²¨ë¶€íŒŒì¼ë“¤
            for j, attachment in enumerate(message.attachments):
                # ì²¨ë¶€íŒŒì¼ ì¸ë„¤ì¼
                thumb = attachment.thumbnail()
                if thumb and thumb.get('src'):
                    total_resources += 1
                    message_resources.append(f"ì²¨ë¶€íŒŒì¼{j+1} ì¸ë„¤ì¼: {thumb['src']}")
                    if self.download_file(thumb['src']):
                        downloaded_count += 1
                
                # ì²¨ë¶€íŒŒì¼ ì‘ì„±ì ì•„ì´ì½˜
                if hasattr(attachment, 'author_icon') and attachment.author_icon:
                    total_resources += 1
                    message_resources.append(f"ì²¨ë¶€íŒŒì¼{j+1} ì‘ì„±ì ì•„ì´ì½˜: {attachment.author_icon}")
                    if self.download_file(attachment.author_icon):
                        downloaded_count += 1
                
                # ì²¨ë¶€íŒŒì¼ í‘¸í„° ì•„ì´ì½˜
                if hasattr(attachment, 'footer_icon') and attachment.footer_icon:
                    total_resources += 1
                    message_resources.append(f"ì²¨ë¶€íŒŒì¼{j+1} í‘¸í„° ì•„ì´ì½˜: {attachment.footer_icon}")
                    if self.download_file(attachment.footer_icon):
                        downloaded_count += 1
            
            # íŒŒì¼ë“¤
            for k, file in enumerate(message.files):
                # íŒŒì¼ ì¸ë„¤ì¼
                thumb = file.thumbnail()
                if thumb and thumb.get('src'):
                    total_resources += 1
                    message_resources.append(f"íŒŒì¼{k+1} ì¸ë„¤ì¼: {thumb['src']}")
                    if self.download_file(thumb['src']):
                        downloaded_count += 1
                
                # íŒŒì¼ ìì²´ ë‹¤ìš´ë¡œë“œ (download_url ì‚¬ìš©)
                file_url = getattr(file, 'download_url', None) or file.link
                if file_url and self._is_slack_cdn_url(file_url):
                    total_resources += 1
                    message_resources.append(f"íŒŒì¼{k+1} ë‹¤ìš´ë¡œë“œ: {file_url}")
                    if self.download_file(file_url):
                        downloaded_count += 1
            
            # ë©”ì‹œì§€ì— ë¦¬ì†ŒìŠ¤ê°€ ìˆìœ¼ë©´ ë¡œê¹…
            if message_resources:
                logging.info(f"ë©”ì‹œì§€ {i+1}: {len(message_resources)}ê°œ ë¦¬ì†ŒìŠ¤ ë°œê²¬")
                print(f"ğŸ“¦ ë©”ì‹œì§€ {i+1}: {len(message_resources)}ê°œ ë¦¬ì†ŒìŠ¤ ë°œê²¬")
                for resource in message_resources:
                    logging.info(f"  - {resource}")
                    print(f"    - {resource}")
        
        logging.info(f"ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print(f"âœ… ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        logging.info(f"  ì´ ë°œê²¬ëœ ë¦¬ì†ŒìŠ¤: {total_resources}ê°œ")
        logging.info(f"  ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ: {downloaded_count}ê°œ")
        logging.info(f"  ë‹¤ìš´ë¡œë“œ í†µê³„: ì‹œë„ {self.stats['total_attempted']}ê°œ, ì„±ê³µ {self.stats['total_success']}ê°œ, ì‹¤íŒ¨ {self.stats['total_failed']}ê°œ, ìŠ¤í‚µ {self.stats['total_skipped']}ê°œ")
        print(f"ğŸ“Š ì´ ë°œê²¬ëœ ë¦¬ì†ŒìŠ¤: {total_resources}ê°œ")
        print(f"ğŸ“Š ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ: {downloaded_count}ê°œ")
        print(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ í†µê³„: ì‹œë„ {self.stats['total_attempted']}ê°œ, ì„±ê³µ {self.stats['total_success']}ê°œ, ì‹¤íŒ¨ {self.stats['total_failed']}ê°œ, ìŠ¤í‚µ {self.stats['total_skipped']}ê°œ")
        
        return downloaded_count, total_resources 